{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors, QED\n",
    "from tensorflow.contrib.keras import preprocessing\n",
    "\n",
    "\n",
    "def get_property(smi):\n",
    "\n",
    "    try:\n",
    "        mol=Chem.MolFromSmiles(smi) \n",
    "        property = [Descriptors.ExactMolWt(mol), Descriptors.MolLogP(mol), QED.qed(mol)]\n",
    "        \n",
    "    except:\n",
    "        property = 'invalid'\n",
    "           \n",
    "    return property\n",
    "    \n",
    "\n",
    "def canonocalize(smi):\n",
    "\n",
    "    return Chem.MolToSmiles(Chem.MolFromSmiles(smi))\n",
    "\n",
    "\n",
    "def vectorize(list_input, char_set):\n",
    "\n",
    "    one_hot = np.zeros((list_input.shape[0], list_input.shape[1]+4, len(char_set)), dtype=np.int32)\n",
    "\n",
    "    for si, ss in enumerate(list_input):\n",
    "        for cj, cc in enumerate(ss):\n",
    "            one_hot[si,cj+1,cc] = 1\n",
    "\n",
    "        one_hot[si,-1,0] = 1\n",
    "        one_hot[si,-2,0] = 1\n",
    "        one_hot[si,-3,0] = 1\n",
    "\n",
    "    return one_hot[:,0:-1,:], one_hot[:,1:,:]\n",
    "\n",
    "\n",
    "def smiles_to_seq(smiles, char_set):\n",
    "\n",
    "    char_to_int = dict((c,i) for i,c in enumerate(char_set))\n",
    "    \n",
    "    list_seq=[]\n",
    "    for s in smiles:\n",
    "        seq=[]                \n",
    "        j=0\n",
    "        while j<len(s):\n",
    "            if j<len(s)-1 and s[j:j+2] in char_set:\n",
    "                seq.append(char_to_int[s[j:j+2]])\n",
    "                j=j+2\n",
    "    \n",
    "            elif s[j] in char_set:\n",
    "                seq.append(char_to_int[s[j]])\n",
    "                j=j+1\n",
    "    \n",
    "        list_seq.append(seq)\n",
    "    \n",
    "    list_seq = preprocessing.sequence.pad_sequences(list_seq, padding='post')\n",
    "    \n",
    "    return list_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class Model(object):\n",
    "\n",
    "    def __init__(self, seqlen_x, dim_x, dim_y, dim_z=100, dim_h=250, n_hidden=3, batch_size=200, beta=10000., char_set=[' ']):\n",
    "\n",
    "        self.seqlen_x, self.dim_x, self.dim_y, self.dim_z, self.dim_h, self.n_hidden, self.batch_size = seqlen_x, dim_x, dim_y, dim_z, dim_h, n_hidden, batch_size\n",
    "        self.beta = beta\n",
    "        \n",
    "        self.char_to_int = dict((c,i) for i,c in enumerate(char_set))\n",
    "        self.int_to_char = dict((i,c) for i,c in enumerate(char_set))\n",
    "        \n",
    "        self.G = tf.Graph()\n",
    "        self.G.as_default()\n",
    "\n",
    "        ## variables for labeled data\n",
    "        self.x_L = tf.placeholder(tf.float32, [None, self.seqlen_x, self.dim_x])\n",
    "        self.xs_L = tf.placeholder(tf.float32, [None, self.seqlen_x, self.dim_x])\n",
    "        self.y_L = tf.placeholder(tf.float32, [None, self.dim_y])\n",
    "\n",
    "        ## functions for labeled data\n",
    "        self.classifier_L_out = self._rnnpredictor(self.x_L, self.dim_h, 2*self.dim_y, reuse = False)\n",
    "        self.y_L_mu, self.y_L_lsgms = tf.split(self.classifier_L_out, [self.dim_y, self.dim_y], 1)\n",
    "        self.y_L_sample = self._draw_sample(self.y_L_mu, self.y_L_lsgms)\n",
    "\n",
    "        self.encoder_L_out = self._rnnencoder(self.x_L, self.y_L, self.dim_h, 2*self.dim_z, reuse = False)\n",
    "        self.z_L_mu, self.z_L_lsgms = tf.split(self.encoder_L_out, [self.dim_z, self.dim_z], 1)\n",
    "        self.z_L_sample = self._draw_sample(self.z_L_mu, self.z_L_lsgms)\n",
    "\n",
    "        self.decoder_L_out = self._rnndecoder(self.xs_L, tf.concat([self.z_L_sample, self.y_L], 1), self.dim_h, self.dim_x, reuse = False)\n",
    "        self.x_L_recon = tf.nn.softmax(self.decoder_L_out)\n",
    "\n",
    "        self.decoder_DL_out = self._rnndecoder(self.xs_L, tf.concat([self.z_L_mu, self.y_L], 1), self.dim_h, self.dim_x, reuse = True)\n",
    "        self.x_DL_recon = tf.nn.softmax(self.decoder_DL_out)\n",
    "\n",
    "        self.z_G = tf.placeholder(tf.float32, [None, dim_z])\n",
    "        self.decoder_G_out = self._rnndecoder(self.xs_L, tf.concat([self.z_G, self.y_L], 1), self.dim_h, self.dim_x, reuse = True)\n",
    "        self.x_G_recon = tf.nn.softmax(self.decoder_G_out)\n",
    "\n",
    "\n",
    "        ## variables for unlabeled data\n",
    "        self.x_U = tf.placeholder(tf.float32, [None, self.seqlen_x, self.dim_x])\n",
    "        self.xs_U = tf.placeholder(tf.float32, [None, self.seqlen_x, self.dim_x])\n",
    "\n",
    "        ## functions for unlabeled data\n",
    "        self.classifier_U_out = self._rnnpredictor(self.x_U, self.dim_h, 2*self.dim_y, reuse = True)\n",
    "        self.y_U_mu, self.y_U_lsgms = tf.split(self.classifier_U_out, [self.dim_y, self.dim_y], 1)\n",
    "        self.y_U_sample = self._draw_sample(self.y_U_mu, self.y_U_lsgms)\n",
    "\n",
    "        self.encoder_U_out = self._rnnencoder(self.x_U, self.y_U_sample, self.dim_h, 2*self.dim_z, reuse = True)\n",
    "        self.z_U_mu, self.z_U_lsgms = tf.split(self.encoder_U_out, [self.dim_z, self.dim_z], 1)\n",
    "        self.z_U_sample = self._draw_sample(self.z_U_mu, self.z_U_lsgms)\n",
    "\n",
    "        self.decoder_U_out = self._rnndecoder(self.xs_U, tf.concat([self.z_U_sample, self.y_U_sample], 1), self.dim_h, self.dim_x, reuse = True)\n",
    "        self.x_U_recon = tf.nn.softmax(self.decoder_U_out)\n",
    "\n",
    "        self.encoder_U2_out = self._rnnencoder(self.x_U, self.y_U_mu, self.dim_h, 2*self.dim_z, reuse = True)\n",
    "        self.z_U2_mu, self.z_U2_lsgms = tf.split(self.encoder_U2_out, [self.dim_z, self.dim_z], 1)\n",
    "        \n",
    "        self.decoder_DU_out = self._rnndecoder(self.xs_U, tf.concat([self.z_U2_mu, self.y_U_mu], 1), self.dim_h, self.dim_x, reuse = True)\n",
    "        self.x_DU_recon = tf.nn.softmax(self.decoder_DU_out)\n",
    "\n",
    "\n",
    "        self.saver = tf.train.Saver()\n",
    "        self.session = tf.Session()\n",
    "        \n",
    "\n",
    "    def train(self, trnX_L, trnXs_L, trnY_L, trnX_U, trnXs_U, valX_L, valXs_L, valY_L, valX_U, valXs_U):\n",
    "\n",
    "        self.mu_prior=np.mean(trnY_L,0)   \n",
    "        self.cov_prior=np.cov(trnY_L.T)     \n",
    "\n",
    "        self.tf_mu_prior=tf.constant(self.mu_prior, shape=[1, self.dim_y], dtype=tf.float32)   \n",
    "        self.tf_cov_prior=tf.constant(self.cov_prior, shape=[self.dim_y, self.dim_y], dtype=tf.float32)\n",
    "\n",
    "\n",
    "        # objective functions\n",
    "        objL = self._obj_L()\n",
    "        objU = self._obj_U()\n",
    "        objYpred_MSE = tf.reduce_mean(tf.reduce_sum(tf.squared_difference(self.y_L, self.y_L_mu), 1))\n",
    "        \n",
    "        objL_val = - tf.reduce_mean(- tf.reduce_sum(self.cross_entropy(tf.layers.flatten(self.x_L), tf.layers.flatten(self.x_DL_recon)), 1))\n",
    "        objU_val = - tf.reduce_mean(- tf.reduce_sum(self.cross_entropy(tf.layers.flatten(self.x_U), tf.layers.flatten(self.x_DU_recon)), 1))\n",
    "\n",
    "        batch_size_L=int(self.batch_size*len(trnX_L)/(len(trnX_L)+len(trnX_U)))\n",
    "        batch_size_U=int(self.batch_size*len(trnX_U)/(len(trnX_L)+len(trnX_U)))\n",
    "        n_batch=int(len(trnX_L)/batch_size_L)\n",
    "        \n",
    "        batch_size_val_L=int(len(valX_L)/10)\n",
    "        batch_size_val_U=int(len(valX_U)/10)\n",
    "\n",
    "        cost = (objL * float(batch_size_L) + objU * float(batch_size_U))/float(batch_size_L+batch_size_U) + float(batch_size_L)/float(batch_size_L+batch_size_U) * (self.beta * objYpred_MSE)\n",
    "        cost_val = objYpred_MSE\n",
    "        train_op = tf.train.AdamOptimizer().minimize(cost)\n",
    "        self.session.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "        # training\n",
    "        val_log=np.zeros(300)\n",
    "        for epoch in range(300):\n",
    "            [trnX_L, trnXs_L, trnY_L]=self._permutation([trnX_L, trnXs_L, trnY_L])\n",
    "            [trnX_U, trnXs_U]=self._permutation([trnX_U, trnXs_U])\n",
    "\n",
    "            for i in range(n_batch):\n",
    "                start_L=i*batch_size_L\n",
    "                end_L=start_L+batch_size_L\n",
    "                \n",
    "                start_U=i*batch_size_U\n",
    "                end_U=start_U+batch_size_U\n",
    "\n",
    "                trn_res = self.session.run([train_op, cost, objL, objU, objYpred_MSE],\n",
    "                                      feed_dict = {self.x_L: trnX_L[start_L:end_L], self.xs_L: trnXs_L[start_L:end_L], self.y_L: trnY_L[start_L:end_L],\n",
    "                                      self.x_U: trnX_U[start_U:end_U], self.xs_U: trnXs_U[start_U:end_U]})\n",
    "\n",
    "            val_res = []\n",
    "            for i in range(10):\n",
    "                start_L=i*batch_size_val_L\n",
    "                end_L=start_L+batch_size_val_L\n",
    "                \n",
    "                start_U=i*batch_size_val_U\n",
    "                end_U=start_U+batch_size_val_U\n",
    "            \n",
    "                val_res.append(self.session.run([cost_val, objL_val, objU_val, objYpred_MSE],\n",
    "                                  feed_dict = {self.x_L: valX_L[start_L:end_L], self.xs_L: valXs_L[start_L:end_L], self.y_L: valY_L[start_L:end_L],\n",
    "                                  self.x_U: valX_U[start_U:end_U], self.xs_U: valXs_U[start_U:end_U]}))\n",
    "            \n",
    "            val_res=np.mean(val_res,axis=0)\n",
    "            print(epoch, ['Training', 'cost_trn', trn_res[1]])\n",
    "            print('---', ['Validation', 'cost_val', val_res[0]])\n",
    "\n",
    "            val_log[epoch] = val_res[0]\n",
    "            if epoch > 20 and np.min(val_log[0:epoch-10]) * 0.99 < np.min(val_log[epoch-10:epoch+1]):\n",
    "                print('---termination condition is met')\n",
    "                break\n",
    "\n",
    "\n",
    "    def predict(self, x_input):\n",
    "\n",
    "        return self.session.run(self.y_U_mu, feed_dict = {self.x_U: x_input})\n",
    "\n",
    "\n",
    "    def latent(self, x_input, y_input):\n",
    "\n",
    "        return self.session.run(self.z_L_mu, feed_dict = {self.x_L: x_input, self.y_L: y_input})\n",
    "\n",
    "\n",
    "    def sampling_unconditional(self): \n",
    "       \n",
    "        sample_z=np.random.randn(1, self.dim_z)\n",
    "        sample_y=np.random.multivariate_normal(self.mu_prior, self.cov_prior, 1)      \n",
    "          \n",
    "        sample_smiles=self.beam_search(sample_z, sample_y, k=5)\n",
    "\n",
    "        return sample_smiles\n",
    "        \n",
    "    \n",
    "    def sampling_conditional(self, yid, ytarget):\n",
    "    \n",
    "        def random_cond_normal(yid, ytarget):\n",
    "\n",
    "            id2=[yid]\n",
    "            id1=np.setdiff1d([0,1,2],id2)\n",
    "        \n",
    "            mu1=self.mu_prior[id1]\n",
    "            mu2=self.mu_prior[id2]\n",
    "            \n",
    "            cov11=self.cov_prior[id1][:,id1]\n",
    "            cov12=self.cov_prior[id1][:,id2]\n",
    "            cov22=self.cov_prior[id2][:,id2]\n",
    "            cov21=self.cov_prior[id2][:,id1]\n",
    "            \n",
    "            cond_mu=np.transpose(mu1.T+np.matmul(cov12, np.linalg.inv(cov22)) * (ytarget-mu2))[0]\n",
    "            cond_cov=cov11 - np.matmul(np.matmul(cov12, np.linalg.inv(cov22)), cov21)\n",
    "            \n",
    "            marginal_sampled=np.random.multivariate_normal(cond_mu, cond_cov, 1)\n",
    "            \n",
    "            tst=np.zeros(3)\n",
    "            tst[id1]=marginal_sampled\n",
    "            tst[id2]=ytarget\n",
    "            \n",
    "            return np.asarray([tst])\n",
    "\n",
    "        sample_z=np.random.randn(1, self.dim_z)\n",
    "        sample_y=random_cond_normal(yid, ytarget) \n",
    "          \n",
    "        sample_smiles=self.beam_search(sample_z, sample_y, k=5)\n",
    "            \n",
    "        return sample_smiles\n",
    "\n",
    "\n",
    "    def beam_search(self, z_input, y_input, k=5):\n",
    "\n",
    "        def reconstruct(xs_input, z_sample, y_input):\n",
    "\n",
    "            return self.session.run(self.x_G_recon, feed_dict = {self.xs_L: xs_input, self.z_G: z_sample, self.y_L: y_input})\n",
    "        \n",
    "        \n",
    "        cands=np.asarray([np.zeros((1, self.seqlen_x, self.dim_x), dtype=np.float32)] )\n",
    "        cands_score=np.asarray([100.])\n",
    "        \n",
    "        for i in range(self.seqlen_x-1):\n",
    "        \n",
    "            cands2=[]\n",
    "            cands2_score=[]\n",
    "\n",
    "            for j, samplevec in enumerate(cands):\n",
    "                o = reconstruct(samplevec, z_input, y_input)\n",
    "                sampleidxs = np.argsort(-o[0,i])[:k]\n",
    "                \n",
    "                for sampleidx in sampleidxs: \n",
    "                    \n",
    "                    samplevectt=np.copy(samplevec)\n",
    "                    samplevectt[0, i+1, sampleidx] = 1.\n",
    "                    \n",
    "                    cands2.append(samplevectt)\n",
    "                    cands2_score.append(cands_score[j] * o[0,i,sampleidx])\n",
    "                    \n",
    "            cands2_score=np.asarray(cands2_score)\n",
    "            cands2=np.asarray(cands2)\n",
    "            \n",
    "            kbestid = np.argsort(-cands2_score)[:k]\n",
    "            cands=np.copy(cands2[kbestid])\n",
    "            cands_score=np.copy(cands2_score[kbestid])\n",
    "            \n",
    "            if np.sum([np.argmax(c[0][i+1]) for c in cands])==0:\n",
    "                break\n",
    "\n",
    "        sampletxt = ''.join([self.int_to_char[np.argmax(t)] for t in cands[0,0]]).strip()\n",
    "\n",
    "        return sampletxt\n",
    "\n",
    "\n",
    "    def _obj_L(self):\n",
    "\n",
    "        L_log_lik = - tf.reduce_sum(self.cross_entropy(tf.layers.flatten(self.x_L), tf.layers.flatten(self.x_L_recon)), 1)\n",
    "        L_log_prior_y = self.noniso_logpdf(self.y_L)\n",
    "        L_KLD_z = self.iso_KLD(self.z_L_mu, self.z_L_lsgms)\n",
    "\n",
    "        objL = - tf.reduce_mean(L_log_lik + L_log_prior_y - L_KLD_z)\n",
    "        \n",
    "        return objL\n",
    "\n",
    "\n",
    "    def _obj_U(self):\n",
    "\n",
    "        U_log_lik = - tf.reduce_sum(self.cross_entropy(tf.layers.flatten(self.x_U), tf.layers.flatten(self.x_U_recon)), 1)\n",
    "        U_KLD_y = self.noniso_KLD(self.y_U_mu, self.y_U_lsgms)\n",
    "        U_KLD_z = self.iso_KLD(self.z_U_mu, self.z_U_lsgms)\n",
    "\n",
    "        objU = - tf.reduce_mean(U_log_lik - U_KLD_y - U_KLD_z)\n",
    "        \n",
    "        return objU\n",
    "\n",
    "\n",
    "    def cross_entropy(self, x, y, const = 1e-10):\n",
    "        return - ( x*tf.log(tf.clip_by_value(y, const, 1.0))+(1.0-x)*tf.log(tf.clip_by_value(1.0-y, const, 1.0)) )\n",
    "\n",
    "\n",
    "    def iso_KLD(self, mu, log_sigma_sq):\n",
    "        return tf.reduce_sum( - 0.5 * (1.0 + log_sigma_sq - tf.square(mu) - tf.exp(log_sigma_sq) ), 1)\n",
    "\n",
    "\n",
    "    def noniso_logpdf(self, x):\n",
    "        return - 0.5 * (float(self.cov_prior.shape[0]) * np.log(2.*np.pi) +  np.log(np.linalg.det(self.cov_prior))\n",
    "                        + tf.reduce_sum( tf.multiply( tf.matmul( tf.subtract(x, self.tf_mu_prior), tf.matrix_inverse(self.tf_cov_prior) ), tf.subtract(x, self.tf_mu_prior) ), 1) )\n",
    "\n",
    "\n",
    "    def noniso_KLD(self, mu, log_sigma_sq):\n",
    "        return 0.5 * ( tf.trace( tf.scan(lambda a, x: tf.matmul(tf.matrix_inverse(self.tf_cov_prior), x), tf.matrix_diag(tf.exp(log_sigma_sq)) ) ) \n",
    "                      + tf.reduce_sum( tf.multiply( tf.matmul( tf.subtract(self.tf_mu_prior, mu), tf.matrix_inverse(self.tf_cov_prior) ), tf.subtract(self.tf_mu_prior, mu) ), 1)\n",
    "                      - float(self.cov_prior.shape[0]) + np.log(np.linalg.det(self.cov_prior)) - tf.reduce_sum(log_sigma_sq, 1) )  \n",
    "\n",
    "\n",
    "    def _permutation(self, set):\n",
    "\n",
    "        permid=np.random.permutation(len(set[0]))\n",
    "        for i in range(len(set)):\n",
    "            set[i]=set[i][permid]\n",
    "\n",
    "        return set\n",
    "\n",
    "\n",
    "    def _draw_sample(self, mu, lsgms):\n",
    "\n",
    "        epsilon = tf.random_normal((tf.shape(mu)), 0, 1)\n",
    "        sample = tf.add(mu, tf.multiply(tf.exp(0.5*lsgms), epsilon))\n",
    "\n",
    "        return sample \n",
    "\n",
    "\n",
    "    def _rnnpredictor(self, x, dim_h, dim_y, reuse=False):\n",
    "\n",
    "        with tf.variable_scope('rnnpredictor', reuse=reuse):\n",
    "\n",
    "            cell_fw = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(dim_h) for _ in range(self.n_hidden)])\n",
    "            cell_bw = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(dim_h) for _ in range(self.n_hidden)])\n",
    "            init_state_fw = cell_fw.zero_state(tf.shape(x)[0], tf.float32)\n",
    "            init_state_bw = cell_bw.zero_state(tf.shape(x)[0], tf.float32)\n",
    "            \n",
    "            _, final_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, x, initial_state_fw=init_state_fw, initial_state_bw=init_state_bw)\n",
    "            res = tf.layers.dense(tf.concat([final_state[0][-1],final_state[1][-1]], 1), dim_y)\n",
    "            \n",
    "            \n",
    "        return res\n",
    "\n",
    "\n",
    "    def _rnnencoder(self, x, st, dim_h, dim_y, reuse=False):\n",
    "\n",
    "        with tf.variable_scope('rnnencoder', reuse=reuse):\n",
    "\n",
    "            cell_fw = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(dim_h) for _ in range(self.n_hidden)])\n",
    "            cell_bw = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(dim_h) for _ in range(self.n_hidden)])\n",
    "            init_state_fw = tf.layers.dense(st, dim_h, activation = tf.nn.sigmoid)\n",
    "            init_state_bw = tf.layers.dense(st, dim_h, activation = tf.nn.sigmoid)\n",
    "            peek_in = tf.layers.dense(st, self.dim_x, activation = tf.nn.sigmoid)\n",
    "            peek = tf.reshape(tf.tile(peek_in, [1, self.seqlen_x]), [-1, self.seqlen_x, self.dim_x])\n",
    "            \n",
    "            _, final_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, tf.concat([x,peek],2),\n",
    "                                initial_state_fw=tuple([init_state_fw]*self.n_hidden), initial_state_bw=tuple([init_state_bw]*self.n_hidden))\n",
    "            res = tf.layers.dense(tf.concat([final_state[0][-1],final_state[1][-1]], 1), dim_y)\n",
    "            \n",
    "            \n",
    "        return res\n",
    "\n",
    "\n",
    "    def _rnndecoder(self, x, st, dim_h, dim_y, reuse=False):\n",
    "\n",
    "        with tf.variable_scope('rnndecoder', reuse=reuse):\n",
    "        \n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.GRUCell(dim_h) for _ in range(self.n_hidden)])\n",
    "            init_state = tf.layers.dense(st, dim_h, activation = tf.nn.sigmoid)\n",
    "            peek_in = tf.layers.dense(st, self.dim_x, activation = tf.nn.sigmoid)\n",
    "            peek = tf.reshape(tf.tile(peek_in, [1, self.seqlen_x]), [-1, self.seqlen_x, self.dim_x])\n",
    "\n",
    "            rnn_outputs, final_state = tf.nn.dynamic_rnn(cell, tf.concat([x,peek],2), initial_state=tuple([init_state]*self.n_hidden))\n",
    "            res = tf.layers.dense(rnn_outputs, dim_y)\n",
    "\n",
    "\n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: data preparation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcolmenarejo/anaconda3/envs/tf35/lib/python3.5/site-packages/ipykernel_launcher.py:28: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "/home/gcolmenarejo/anaconda3/envs/tf35/lib/python3.5/site-packages/ipykernel_launcher.py:29: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: model training\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable rnnpredictor/bidirectional_rnn/fw/multi_rnn_cell/cell_0/gru_cell/gates/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/gcolmenarejo/cmd/SSVAE.py\", line 304, in _rnnpredictor\n    _, final_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, x, initial_state_fw=init_state_fw, initial_state_bw=init_state_bw)\n  File \"/home/gcolmenarejo/cmd/SSVAE.py\", line 26, in __init__\n    self.classifier_L_out = self._rnnpredictor(self.x_L, self.dim_h, 2*self.dim_y, reuse = False)\n  File \"<ipython-input-4-a505a6035ec3>\", line 83, in <module>\n    n_hidden = n_hidden, batch_size = batch_size, beta = float(beta), char_set = char_set)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a505a6035ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m model = SSVAE.Model(seqlen_x = seqlen_x, dim_x = dim_x, dim_y = dim_y, dim_z = dim_z, dim_h = dim_h,\n\u001b[0;32m---> 83\u001b[0;31m                     n_hidden = n_hidden, batch_size = batch_size, beta = float(beta), char_set = char_set)\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cmd/SSVAE.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, seqlen_x, dim_x, dim_y, dim_z, dim_h, n_hidden, batch_size, beta, char_set)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m## functions for labeled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_L_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rnnpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_L\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_L_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_L_lsgms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier_L_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim_y\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_L_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_L_mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_L_lsgms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cmd/SSVAE.py\u001b[0m in \u001b[0;36m_rnnpredictor\u001b[0;34m(self, x, dim_h, dim_y, reuse)\u001b[0m\n\u001b[1;32m    302\u001b[0m             \u001b[0minit_state_bw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell_bw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidirectional_dynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell_fw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_bw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state_fw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_state_fw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state_bw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_state_bw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfinal_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mbidirectional_dynamic_rnn\u001b[0;34m(cell_fw, cell_bw, inputs, sequence_length, initial_state_fw, initial_state_bw, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    414\u001b[0m           \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state_fw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m           \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m           time_major=time_major, scope=fw_scope)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;31m# Backward direction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    826\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   3230\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3231\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 3232\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   3233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3234\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2950\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2951\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2952\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2953\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2954\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2885\u001b[0m         flat_sequence=vars_for_body_with_tensor_arrays)\n\u001b[1;32m   2886\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2887\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2888\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2889\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbody_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   3199\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   3200\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 3201\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3203\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    797\u001b[0m           skip_conditionals=True)\n\u001b[1;32m    798\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;31m# Pack state if using state tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0minput_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_sequence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope_attrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNNCell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    734\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m           raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, state)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                                       [-1, cell.state_size])\n\u001b[1;32m   1314\u001b[0m           \u001b[0mcur_state_pos\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m         \u001b[0mcur_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_inp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m         \u001b[0mnew_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;31m# method.  See the class docstring for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     return base_layer.Layer.__call__(self, inputs, state, scope=scope,\n\u001b[0;32m--> 329\u001b[0;31m                                      *args, **kwargs)\n\u001b[0m\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, inputs_shape)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;34m\"gates/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_WEIGHTS_VARIABLE_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_depth\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_units\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m         initializer=self._kernel_initializer)\n\u001b[0m\u001b[1;32m    453\u001b[0m     self._gate_bias = self.add_variable(\n\u001b[1;32m    454\u001b[0m         \u001b[0;34m\"gates/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_BIAS_VARIABLE_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;34m\"\"\"Alias for `add_weight`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 461\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m   def add_weight(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             getter=vs.get_variable)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, getter)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    533\u001b[0m     new_variable = getter(\n\u001b[1;32m    534\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1465\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1215\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    508\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"constraint\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"constraint\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m       return _true_getter(\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m_rnn_get_variable\u001b[0;34m(self, getter, *args, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_rnn_get_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m     \u001b[0mvariable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m       \u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trainable\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    479\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf35/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    846\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 848\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable rnnpredictor/bidirectional_rnn/fw/multi_rnn_cell/cell_0/gru_cell/gates/kernel already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/home/gcolmenarejo/cmd/SSVAE.py\", line 304, in _rnnpredictor\n    _, final_state = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, x, initial_state_fw=init_state_fw, initial_state_bw=init_state_bw)\n  File \"/home/gcolmenarejo/cmd/SSVAE.py\", line 26, in __init__\n    self.classifier_L_out = self._rnnpredictor(self.x_L, self.dim_h, 2*self.dim_y, reuse = False)\n  File \"<ipython-input-4-a505a6035ec3>\", line 83, in <module>\n    n_hidden = n_hidden, batch_size = batch_size, beta = float(beta), char_set = char_set)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pds\n",
    "from preprocessing import smiles_to_seq, vectorize\n",
    "import SSVAE\n",
    "\n",
    "from preprocessing import get_property, canonocalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "\n",
    "# pre-defined parameters\n",
    "frac=0.5\n",
    "beta=10000.\n",
    "char_set=[' ','1','2','3','4','5','6','7','8','9','-','#','(',')','[',']','+','=','B','Br','c','C','Cl','F','H','I','N','n','O','o','P','p','S','s','Si','Sn']\n",
    "data_uri='./data/ZINC_310k.csv'\n",
    "save_uri='./zinc_model.ckpt'\n",
    "\n",
    "ntrn=300000\n",
    "frac_val=0.05\n",
    "ntst=10000\n",
    "\n",
    "\n",
    "# data preparation\n",
    "print('::: data preparation')\n",
    "\n",
    "smiles = pds.read_csv(data_uri).as_matrix()[:ntrn+ntst,0] #0: SMILES\n",
    "Y = np.asarray(pds.read_csv(data_uri).as_matrix()[:ntrn+ntst,1:], dtype=np.float32) # 1: MolWT, 2: LogP, 3: QED \n",
    "\n",
    "list_seq = smiles_to_seq(smiles, char_set)\n",
    "Xs, X=vectorize(list_seq, char_set)\n",
    "\n",
    "tstX=X[-ntst:]\n",
    "tstXs=Xs[-ntst:]\n",
    "tstY=Y[-ntst:]\n",
    "\n",
    "X=X[:ntrn]\n",
    "Xs=Xs[:ntrn]\n",
    "Y=Y[:ntrn]\n",
    "\n",
    "nL=int(len(Y)*frac)\n",
    "nU=len(Y)-nL\n",
    "nL_trn=int(nL*(1-frac_val))\n",
    "nL_val=nL-nL_trn\n",
    "nU_trn=int(nU*(1-frac_val))\n",
    "nU_val=nU-nU_trn\n",
    "perm_id=np.random.permutation(len(Y))\n",
    "\n",
    "trnX_L=X[perm_id[:nL_trn]]\n",
    "trnXs_L=Xs[perm_id[:nL_trn]]\n",
    "trnY_L=Y[perm_id[:nL_trn]]\n",
    "\n",
    "valX_L=X[perm_id[nL_trn:nL_trn+nL_val]]\n",
    "valXs_L=Xs[perm_id[nL_trn:nL_trn+nL_val]]\n",
    "valY_L=Y[perm_id[nL_trn:nL_trn+nL_val]]\n",
    "\n",
    "trnX_U=X[perm_id[nL_trn+nL_val:nL_trn+nL_val+nU_trn]]\n",
    "trnXs_U=Xs[perm_id[nL_trn+nL_val:nL_trn+nL_val+nU_trn]]\n",
    "\n",
    "valX_U=X[perm_id[nL_trn+nL_val+nU_trn:]]\n",
    "valXs_U=Xs[perm_id[nL_trn+nL_val+nU_trn:]]\n",
    "\n",
    "scaler_Y = StandardScaler()\n",
    "scaler_Y.fit(Y)\n",
    "trnY_L=scaler_Y.transform(trnY_L)\n",
    "valY_L=scaler_Y.transform(valY_L)\n",
    "\n",
    "\n",
    "## model training\n",
    "print('::: model training')\n",
    "\n",
    "seqlen_x = X.shape[1]\n",
    "dim_x = X.shape[2]\n",
    "dim_y = Y.shape[1]\n",
    "dim_z = 100\n",
    "dim_h = 250\n",
    "\n",
    "n_hidden = 3\n",
    "batch_size = 200\n",
    "\n",
    "model = SSVAE.Model(seqlen_x = seqlen_x, dim_x = dim_x, dim_y = dim_y, dim_z = dim_z, dim_h = dim_h,\n",
    "                    n_hidden = n_hidden, batch_size = batch_size, beta = float(beta), char_set = char_set)\n",
    "\n",
    "with model.session:\n",
    "    model.train(trnX_L=trnX_L, trnXs_L=trnXs_L, trnY_L=trnY_L, trnX_U=trnX_U, trnXs_U=trnXs_U,\n",
    "                valX_L=valX_L, valXs_L=valXs_L, valY_L=valY_L, valX_U=valX_U, valXs_U=valXs_U)\n",
    "    model.saver.save(model.session, save_uri)\n",
    "\n",
    "    ## property prediction performance\n",
    "    tstY_hat=scaler_Y.inverse_transform(model.predict(tstX))\n",
    "\n",
    "    for j in range(dim_y):\n",
    "        print([j, mean_absolute_error(tstY[:,j], tstY_hat[:,j])])\n",
    "        \n",
    "        \n",
    "    ## unconditional generation\n",
    "    for t in range(10):\n",
    "        smi = model.sampling_unconditional()\n",
    "        print([t, smi, get_property(smi)])\n",
    "    \n",
    "    ## conditional generation (e.g. MolWt=250)\n",
    "    yid = 0\n",
    "    ytarget = 250.\n",
    "    ytarget_transform = (ytarget-scaler_Y.mean_[yid])/np.sqrt(scaler_Y.var_[yid])\n",
    "    \n",
    "    for t in range(10):\n",
    "        smi = model.sampling_conditional(yid, ytarget_transform)\n",
    "        print([t, smi, get_property(smi)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pds\n",
    "import numpy as np\n",
    "\n",
    "# pre-defined parameters\n",
    "frac=0.5\n",
    "beta=10000.\n",
    "char_set=[' ','1','2','3','4','5','6','7','8','9','-','#','(',')','[',']','+','=','B','Br','c','C','Cl','F','H','I','N','n','O','o','P','p','S','s','Si','Sn']\n",
    "\n",
    "data_uri='data/np.csv'\n",
    "save_uri='./np_model.ckpt'\n",
    "\n",
    "ntrn=82452\n",
    "frac_val=0.05\n",
    "ntst=2748\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "::: data preparation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gcolmenarejo/anaconda3/envs/tf35/lib/python3.5/site-packages/ipykernel_launcher.py:4: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  after removing the cwd from sys.path.\n",
      "/home/gcolmenarejo/anaconda3/envs/tf35/lib/python3.5/site-packages/ipykernel_launcher.py:5: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# data preparation\n",
    "print('::: data preparation')\n",
    "\n",
    "smiles = pds.read_csv(data_uri).as_matrix()[:ntrn+ntst,0] #0: SMILES\n",
    "Y = np.asarray(pds.read_csv(data_uri).as_matrix()[:ntrn+ntst,1:], dtype=np.float32) # 1: MolWT, 2: LogP, 3: QED \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C=C1C(=O)O[C@H]2C[C@@H](C)[C@@H]3CCC(=O)[C@@]3(C)C[C@H]12',\n",
       "       'CC(=O)O[C@@H]1c2c(C)coc2C(=O)[C@@]23O[C@@H]2CC[C@H](C)[C@@]13C',\n",
       "       'C/C=C(\\\\C)C(=O)O[C@H]1C=C(CO)C(=O)[C@H](OC(C)=O)[C@H]1C(C)C', ...,\n",
       "       'CC(C)[C@@H]1C=C[C@]2(C)O[C@H]2C1',\n",
       "       'CCCCCCCCCCCCCC(CCCCCCCCCC)CCCCCCCCCC', 'C=CCC[C@H](O)CCC'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.4832201e+02, 2.4995000e+00, 4.8843050e-01],\n",
       "       [3.0434201e+02, 2.9623201e+00, 5.8910120e-01],\n",
       "       [3.2437299e+02, 1.5697000e+00, 6.0969359e-01],\n",
       "       ...,\n",
       "       [1.5223700e+02, 2.3759999e+00, 4.1489872e-01],\n",
       "       [4.7893399e+02, 1.3365300e+01, 8.9990266e-02],\n",
       "       [1.2821500e+02, 2.1136000e+00, 5.6213307e-01]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-05f7865fc5b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlist_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmiles_to_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchar_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-dce3f004e40a>\u001b[0m in \u001b[0;36msmiles_to_seq\u001b[0;34m(smiles, char_set)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchar_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mseq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_to_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_seq = smiles_to_seq(smiles, char_set)\n",
    "Xs, X=vectorize(list_seq, char_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
