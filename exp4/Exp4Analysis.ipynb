{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import myfunc at cix folder\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../cix')\n",
    "\n",
    "import myfuncs as mf\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from rdkit import rdBase\n",
    "rdBase.DisableLog('rdApp.*') # To make rdkit silent\n",
    "\n",
    "from rdkit.Chem import PandasTools as pt\n",
    "\n",
    "from rdkit.Chem import Descriptors\n",
    "\n",
    "from chemfp import search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this script is to analyze the output of the CMD trained with a diverse set of 300K dissimilar (\"orthogonal\") compounds as created by the divsamp0 function and compare it with the output of the CMD trained with a clustered set of 300K compounds. As source of compounds, the set of ca. 5 million clean lead-like compounds from ZINC12 is used. From it, a collection of 300K orthogonal molecules were previously sampled by means of divsamp0 (see Exp4DivSamp script). \n",
    "\n",
    "The correctness, diversity and novelty of the output obtained with the orthogonal training set is compared with the output of the random training set. The correctness of the training and output files is assessed by the percentage of correct SMILES. The diversity of the training and output files are assessed by counting the number of clusters, frames and generic frames in both sets. The novelty of the training set is assessed by the percentage of molecules with a Tanimoto similarity < 0.7 to any molecule in the training set, and the percentage of frames or generic frames not present in the training set.\n",
    "\n",
    "In an initial step, the orthogonality of the orthogonal set is checked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-bd9b3a0eb561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmidf2arena\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msmidf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0msim_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold_tanimoto_search_symmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Sum of neighbors in the similarity table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'search' is not defined"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "## Check orthogonality of input smiles\n",
    "##########################################\n",
    "\n",
    "# Init the time counter for the whole notebook\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "smis = mf.smif2smis('./divtrain300000.smi')\n",
    "ncorr, n, smis, wrongsmis = mf.corrsmis(smis)\n",
    "smidf = mf.smis2smidf(smis)\n",
    "ar = mf.smidf2arena(smidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1801076"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_t = search.threshold_tanimoto_search_symmetric(ar, threshold=0.75)\n",
    "\n",
    "# Sum of neighbors in the similarity table\n",
    "sum([len(indices) for (i,indices) in enumerate(sim_t.iter_indices())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## Analysis of the unconditioned output - diverse set\n",
    "##########################################################\n",
    "\n",
    "# Init the time counter for the whole notebook\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "it = range(50000, 300001, 50000)\n",
    "\n",
    "df_un_d, cls_un_d = mf.wholean(it = it, name_train = \"div0letrain\", name_pref = \"div0leunc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results in the output dataframe\n",
    "\n",
    "df_un_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "\n",
    "df_un_d.to_csv(\"analysis1-div-un.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters distributions and cluster size distribution\n",
    "mf.plotmulticlus(cls_un_d, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## Analysis of the conditioned output - diverse set\n",
    "##########################################################\n",
    "\n",
    "df_co_d, cls_co_d = mf.wholean(it = it, name_train = \"div0letrain\", name_pref = \"div0lecon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results dataframe\n",
    "\n",
    "df_co_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results dataframe\n",
    "\n",
    "df_co_d.to_csv(\"analysis1-div-co.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters distributions and cluster size distribution\n",
    "\n",
    "mf.plotmulticlus(cls_co_d, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the bunch of histograms of mwt\n",
    "\n",
    "mwts = []\n",
    "\n",
    "for n in it:\n",
    "    smis = mf.smif2smis('./div0lecon' + str(n) + '.smi')\n",
    "    ncorr, n, smis, wrongsmis = mf.corrsmis(smis)\n",
    "    smidf = mf.smis2smidf(smis)\n",
    "    pt.AddMoleculeColumnToFrame(smidf,\"smiles\")\n",
    "    smidf['mw'] = smidf['ROMol'].map(Descriptors.MolWt)\n",
    "    del smidf[\"ROMol\"]\n",
    "    mwts.append(list(smidf['mw']))\n",
    "\n",
    "leg = [\"# train=300K\"] \n",
    "\n",
    "mf.paintmultihist([mwts], \"MWt\", 1, 1, 270, 300, 5, 5, 210, 400, leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## Analysis of the unconditioned output - clustered set\n",
    "##########################################################\n",
    "\n",
    "it = range(50000, 300001, 50000)\n",
    "\n",
    "df_un_c, cls_un_c = mf.wholean(it = it, name_train = \"clutrain\", name_pref = \"cluunc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results in the output dataframe\n",
    "\n",
    "df_un_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "\n",
    "df_un_c.to_csv(\"analysis1-clu-un.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters distributions and cluster size distribution\n",
    "mf.plotmulticlus(cls_un_c, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## Analysis of the conditioned output - clustered set\n",
    "##########################################################\n",
    "\n",
    "df_co_c, cls_co_c = mf.wholean(it = it, name_train = \"clutrain\", name_pref = \"clucon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results dataframe\n",
    "\n",
    "df_co_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results dataframe\n",
    "\n",
    "df_co_c.to_csv(\"analysis1-clu-co.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters distributions and cluster size distribution\n",
    "\n",
    "mf.plotmulticlus(cls_co_c, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the bunch of histograms of mwt\n",
    "it = range(300000, 300001)\n",
    "mwts = []\n",
    "\n",
    "for n in it:\n",
    "    smis = mf.smif2smis('./clucon' + str(n) + '.smi')\n",
    "    ncorr, n, smis, wrongsmis = mf.corrsmis(smis)\n",
    "    smidf = mf.smis2smidf(smis)\n",
    "    pt.AddMoleculeColumnToFrame(smidf,\"smiles\")\n",
    "    smidf['mw'] = smidf['ROMol'].map(Descriptors.MolWt)\n",
    "    del smidf[\"ROMol\"]\n",
    "    mwts.append(list(smidf['mw']))\n",
    "\n",
    "leg = [\"# train=300K\"] \n",
    "\n",
    "mf.paintmultihist(mwts, \"MWt\", 1, 1, 270, 300, 5, 5, 210, 400, leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the time counter for the whole notebook\n",
    "end = time.time()\n",
    "eltime = end - start\n",
    "print('Exp4nalysis execution time: ' + time.strftime(\"%H:%M:%S\", time.gmtime(eltime)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
