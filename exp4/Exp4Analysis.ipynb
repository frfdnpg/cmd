{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import myfunc at cix folder\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(0, '../cix')\n",
    "import myfuncs as mf\n",
    "import pandas as pd\n",
    "from rdkit.Chem import rdBase, RDConfig\n",
    "from rdkit import Chem\n",
    "rdBase.DisableLog('rdApp.*') # To make rdkit silent\n",
    "from rdkit.Chem import PandasTools as pt\n",
    "from rdkit.Chem import Descriptors\n",
    "import numpy as np\n",
    "import chemfp\n",
    "import csv\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this script is to analyze the output of the CMD trained with a diverse set of 300K dissimilar (\"orthogonal\") compounds as created by the divsamp0 function and compare it with the output of the CMD trained with a clustered set of 300K compounds. As source of compounds, the set of ca. 5 million clean lead-like compounds from ZINC12 is used. From it, a collection of 300K orthogonal molecules were previously sampled by means of divsamp0 (see Exp4DivSamp script). \n",
    "\n",
    "The correctness, diversity and novelty of the output obtained with the orthogonal training set is compared with the output of the random training set. The correctness of the training and output files is assessed by the percentage of correct SMILES. The diversity of the training and output files are assessed by counting the number of clusters, frames and generic frames in both sets. The novelty of the training set is assessed by the percentage of molecules with a Tanimoto similarity < 0.7 to any molecule in the training set, and the percentage of frames or generic frames not present in the training set.\n",
    "\n",
    "In an initial step, the orthogonality of the orthogonal set is checked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################\n",
    "## Check orthogonality of input smiles\n",
    "##########################################\n",
    "\n",
    "# Init the time counter for the whole notebook\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "smis = mf.smif2smis('./div0le-train-300000.smi')\n",
    "ncorr, n, smis, wrongsmis = mf.corrsmis(smis)\n",
    "smidf = mf.smis2smidf(smis)\n",
    "ar = mf.smidf2arena(smidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1801076"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_t = search.threshold_tanimoto_search_symmetric(ar, threshold=0.75)\n",
    "\n",
    "# Sum of neighbors in the similarity table\n",
    "sum([len(indices) for (i,indices) in enumerate(sim_t.iter_indices())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File ../div0le.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-a1f8558a68a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 2D plot of MW vs logP of training set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata_uri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'../div0le.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_uri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"logp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbidiplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MWt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"LogP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gcolmenarejo/anaconda3/envs/cix/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gcolmenarejo/anaconda3/envs/cix/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gcolmenarejo/anaconda3/envs/cix/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gcolmenarejo/anaconda3/envs/cix/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/gcolmenarejo/anaconda3/envs/cix/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File ../div0le.csv does not exist"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "## Analysis of the unconditioned output - diverse set\n",
    "##########################################################\n",
    "\n",
    "# Init the time counter for the whole notebook\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "# 2D plot of MW vs logP of training set\n",
    "data_uri='../div0le.csv'\n",
    "Y = pd.read_csv(data_uri)\n",
    "Y = Y[[\"mw\", \"logp\"]]\n",
    "mf.bidiplot(np.asarray(Y), \"MWt\",\"LogP\", d = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "it = range(100000, 300001, 100000)\n",
    "\n",
    "df_un_d, cls_un_d = mf.wholean(it = it, name_train = \"div0le-train-\", name_pref = \"div0le-unc2-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results in the output dataframe\n",
    "\n",
    "df_un_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "\n",
    "df_un_d.to_csv(\"analysis2-div-un.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters distributions and cluster size distribution\n",
    "mf.plotmulticlus(cls_un_d, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## Analysis of the conditioned output - diverse set\n",
    "##########################################################\n",
    "\n",
    "df_co_d, cls_co_d = mf.wholean(it = it, name_train = \"div0le-train-\", name_pref = \"div0le-con2-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results dataframe\n",
    "\n",
    "df_co_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results dataframe\n",
    "\n",
    "df_co_d.to_csv(\"analysis2-div-co.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters distributions and cluster size distribution\n",
    "\n",
    "mf.plotmulticlus(cls_co_d, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the bunch of histograms of mwt\n",
    "\n",
    "mwts = []\n",
    "\n",
    "for n in it:\n",
    "    smis = mf.smif2smis('./div0le-con2-' + str(n) + '.smi')\n",
    "    ncorr, n, smis, wrongsmis = mf.corrsmis(smis)\n",
    "    smidf = mf.smis2smidf(smis)\n",
    "    pt.AddMoleculeColumnToFrame(smidf,\"smiles\")\n",
    "    smidf['mw'] = smidf['ROMol'].map(Descriptors.MolWt)\n",
    "    del smidf[\"ROMol\"]\n",
    "    mwts.append(list(smidf['mw']))\n",
    "\n",
    "leg = [\"# train=100K\",\"# train=200K\",\"# train=300K\"] \n",
    "\n",
    "mf.paintmultihist([mwts], \"MWt\", 1, 1, 270, 300, 5, 5, 210, 400, leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D plot of MW vs logP of output set\n",
    "smis = mf.smif2smis('./div0le-con2-300000.smi')\n",
    "ncorr, n, smis, wrongsmis = mf.corrsmis(smis)\n",
    "smidf = mf.smis2smidf(smis)\n",
    "smidf['mol'] = smidf['smiles'].apply(Chem.MolFromSmiles)\n",
    "smidf['mwt'] = smidf['mol'].apply(Descriptors.MolWt)\n",
    "smidf['logp'] = smidf['mol'].apply(Descriptors.MolLogP)\n",
    "smidf = smidf[[\"mwt\",\"logp\"]]\n",
    "mf.bidiplot(np.asarray(smidf), \"MWt\",\"LogP\", d = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## Analysis of the unconditioned output - clustered set\n",
    "##########################################################\n",
    "\n",
    "it = range(100000, 300001, 100000)\n",
    "\n",
    "\n",
    "# 2D plot of MW vs logP of training set\n",
    "data_uri='../clusle.csv'\n",
    "Y = pd.read_csv(data_uri)\n",
    "Y = Y[[\"mw\", \"logp\"]]\n",
    "mf.bidiplot(np.asarray(Y), \"MWt\",\"LogP\", d = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whole analysis\n",
    "df_un_c, cls_un_c = mf.wholean(it = it, name_train = \"clusle-train-\", name_pref = \"clusle-unc2-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results in the output dataframe\n",
    "\n",
    "df_un_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "\n",
    "df_un_c.to_csv(\"analysis2-clu-un.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters distributions and cluster size distribution\n",
    "mf.plotmulticlus(cls_un_c, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################\n",
    "## Analysis of the conditioned output - clustered set\n",
    "##########################################################\n",
    "\n",
    "df_co_c, cls_co_c = mf.wholean(it = it, name_train = \"clusle-train-\", name_pref = \"clusle-con2-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results dataframe\n",
    "\n",
    "df_co_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results dataframe\n",
    "\n",
    "df_co_c.to_csv(\"analysis2-clu-co.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clusters distributions and cluster size distribution\n",
    "\n",
    "mf.plotmulticlus(cls_co_c, 10, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot the bunch of histograms of mwt\n",
    "mwts = []\n",
    "\n",
    "for n in it:\n",
    "    smis = mf.smif2smis('./clusle-con2-' + str(n) + '.smi')\n",
    "    ncorr, n, smis, wrongsmis = mf.corrsmis(smis)\n",
    "    smidf = mf.smis2smidf(smis)\n",
    "    pt.AddMoleculeColumnToFrame(smidf,\"smiles\")\n",
    "    smidf['mw'] = smidf['ROMol'].map(Descriptors.MolWt)\n",
    "    del smidf[\"ROMol\"]\n",
    "    mwts.append(list(smidf['mw']))\n",
    "\n",
    "leg = [\"# train=100K\",\"# train=200K\",\"# train=300K\"] \n",
    "\n",
    "mf.paintmultihist(mwts, \"MWt\", 1, 1, 270, 300, 5, 5, 210, 400, leg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D plot of MW vs logP of output set\n",
    "smis = mf.smif2smis('./clusle-con2-300000.smi')\n",
    "ncorr, n, smis, wrongsmis = mf.corrsmis(smis)\n",
    "smidf = mf.smis2smidf(smis)\n",
    "smidf['mol'] = smidf['smiles'].apply(Chem.MolFromSmiles)\n",
    "smidf['mwt'] = smidf['mol'].apply(Descriptors.MolWt)\n",
    "smidf['logp'] = smidf['mol'].apply(Descriptors.MolLogP)\n",
    "smidf = smidf[[\"mwt\",\"logp\"]]\n",
    "mf.bidiplot(np.asarray(smidf), \"MWt\",\"LogP\", d = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# End the time counter for the whole notebook\n",
    "end = time.time()\n",
    "eltime = end - start\n",
    "print('Exp4nalysis execution time: ' + time.strftime(\"%H:%M:%S\", time.gmtime(eltime)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
